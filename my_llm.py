import os
import openai
from dotenv import load_dotenv

load_dotenv()
openai.api_key = os.getenv("GROQ_API_KEY")
openai.api_base = "https://api.groq.com/openai/v1"

def get_recommendation(symbol: str, fundamentals: dict, technicals: dict, sentiment: str) -> str:
    prompt = f"""
You are a stock advisor for beginners.

Use only the following **real-time data** to recommend:
- BUY RANGE: Based on technical **Support levels**
- SELL TARGET: Based on **Resistance**
- STOP LOSS: 5â€“8% below the support level
- Add a one-line reasoning and one caution/risk.

ğŸ“Œ Stock Symbol: {symbol}

ğŸ“Š Technical Indicators:
{technicals}

ğŸ“‰ Fundamental Snapshot:
{fundamentals}

ğŸ“° Market Sentiment:
{sentiment}

ğŸ‘‰ Give your advice in **this format**, markdown supported:

**ğŸŸ¢ Recommendation**: Buy / Sell / Hold  
**âœ… Buy Range**: â‚¹xxx â€“ â‚¹xxx *(based on support)*  
**ğŸ“ˆ Target Sell Price**: â‚¹xxx *(near resistance)*  
**ğŸ›‘ Stop Loss**: â‚¹xxx  
**ğŸ§  Why**: <1-line simple reason>  
**âš ï¸ Risk**: <1-line risk>

ğŸ¯ Keep it short, clear, and data-driven. No historical info or guessing.
"""

    try:
        response = openai.ChatCompletion.create(
            model="llama3-70b-8192",
            temperature=0,
            messages=[
                {"role": "system", "content": "You provide data-based, updated, beginner-friendly stock advice."},
                {"role": "user", "content": prompt}
            ]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print("LLM Error:", e)
        return "âŒ Recommendation could not be generated."
